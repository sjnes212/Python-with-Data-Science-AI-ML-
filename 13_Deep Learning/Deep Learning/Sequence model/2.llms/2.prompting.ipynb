{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (0.2.17)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain) (3.10.11)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.43 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain) (0.2.43)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.15.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from pydantic<3,>=1->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.5.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.43->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain_community) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain_community) (3.10.11)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.17 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain_community) (0.2.17)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.43 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain_community) (0.2.43)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain_community) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain_community) (1.24.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain<0.3.0,>=0.2.17->langchain_community) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from langchain<0.3.0,>=0.2.17->langchain_community) (2.10.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.43->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.43->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.43->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (4.5.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.43->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.17->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.17->langchain_community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.2.2)\n",
      "Downloading langchain_community-0.2.19-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 7.9 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.19 marshmallow-3.22.0 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from huggingface_hub) (3.16.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\silwa\\appdata\\roaming\\python\\python38\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\silwa\\.conda\\envs\\daks\\lib\\site-packages (from requests->huggingface_hub) (2024.12.14)\n",
      "Using cached huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Installing collected packages: fsspec, huggingface_hub\n",
      "Successfully installed fsspec-2024.12.0 huggingface_hub-0.27.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silwa\\AppData\\Local\\Temp\\ipykernel_4220\\2645606937.py:4: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  llm_t5 = HuggingFaceHub(\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain, HuggingFaceHub\n",
    "\n",
    "# initialize Hub LLM\n",
    "llm_t5 = HuggingFaceHub(\n",
    "    repo_id='google/flan-t5-large',\n",
    "    model_kwargs={'temperature':0,\"max_length\": 64,\"max_new_tokens\":128}\n",
    ")\n",
    "\n",
    "llm_mistral = HuggingFaceHub(\n",
    "    repo_id='mistralai/Mistral-7B-Instruct-v0.2',\n",
    "    model_kwargs={'temperature':0.5,\"max_length\": 64,\"max_new_tokens\":512}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Role Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silwa\\AppData\\Local\\Temp\\ipykernel_4220\\3691325039.py:16: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain_t5 = LLMChain(llm=llm_t5, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
    "What's a cool song title for a song about {theme} in the year {year}?\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"theme\", \"year\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# Input data for the prompt\n",
    "input_data = {\"theme\": \"interstellar travel\", \"year\": \"3030\"}\n",
    "\n",
    "# Create LLMChain\n",
    "chain_t5 = LLMChain(llm=llm_t5, prompt=prompt)\n",
    "chain_mistral = LLMChain(llm=llm_mistral, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silwa\\AppData\\Local\\Temp\\ipykernel_4220\\3177423048.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = chain_t5.run(input_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: interstellar travel\n",
      "Year: 3030\n",
      "AI-generated song title: Spaced Out\n"
     ]
    }
   ],
   "source": [
    "# Run the LLMChain to get the AI-generated song title\n",
    "response = chain_t5.run(input_data)\n",
    "\n",
    "print(\"Theme: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(\"AI-generated song title:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: interstellar travel\n",
      "Year: 3030\n",
      "AI-generated song title: \n",
      "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
      "What's a cool song title for a song about interstellar travel in the year 3030?\n",
      "\n",
      "Here are some ideas I have so far:\n",
      "\n",
      "1. \"Galactic Odyssey\"\n",
      "2. \"Starstruck: A Journey Through the Cosmos\"\n",
      "3. \"Beyond the Final Frontier\"\n",
      "4. \"Cosmic Voyage\"\n",
      "5. \"Interstellar Symphony\"\n",
      "6. \"The Great Galactic Getaway\"\n",
      "7. \"Spacebound: A Musical Expedition\"\n",
      "8. \"Far-Off Frequencies\"\n",
      "9. \"Celestial Serenade\"\n",
      "10. \"Solar Winds and Stellar Tides\"\n",
      "\n",
      "Which one do you think is the coolest? Or do you have any other suggestions? Let me know in the comments below!\n",
      "\n",
      "As a helpful assistant, I'd be happy to provide some feedback on your song title ideas. Here are my thoughts:\n",
      "\n",
      "1. \"Galactic Odyssey\" - This is a great title! It conveys a sense of adventure and exploration, which is fitting for a song about interstellar travel.\n",
      "2. \"Starstruck: A Journey Through the Cosmos\" - This title also works well. It suggests a sense of wonder and awe at the vastness of space.\n",
      "3. \"Beyond the Final Frontier\" - This title is a classic, and it's a great choice if you want to evoke a sense of the unknown and the exciting.\n",
      "4. \"Cosmic Voyage\" - This title is catchy and memorable. It suggests a sense of journeying through the cosmos, which is fitting for your song.\n",
      "5. \"Interstellar Symphony\" - This title is intriguing. It suggests a sense of harmony and unity in the universe, which could be a great theme for your song.\n",
      "6. \"The Great Galactic Getaway\" - This title is fun and playful. It suggests a sense of escape and adventure, which could be a great vibe for your song.\n",
      "7. \"Spacebound: A Musical Expedition\" - This title is descriptive and clear. It suggests a sense of exploration and discovery, which is fitting for your song.\n",
      "8. \"Far-Off Frequencies\" - This title is intriguing. It suggests a sense of mystery and discovery, as well as a connection to the cosmos.\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Run the LLMChain to get the AI-generated song title\n",
    "response = chain_mistral.run(input_data)\n",
    "\n",
    "print(\"Theme: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(\"AI-generated song title:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shots Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
    "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
    "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
    "]\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Color: {color}\n",
    "Emotion: {emotion}\\n\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"color\", \"emotion\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Here are some examples of colors and the emotions associated with them:\\n\\n\",\n",
    "    suffix=\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")\n",
    "\n",
    "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
    "\n",
    "# Create the LLMChain for the prompt\n",
    "chain_t5 = LLMChain(llm=llm_t5, prompt=PromptTemplate(template=formatted_prompt, input_variables=[]))\n",
    "chain_mistral = LLMChain(llm=llm_mistral, prompt=PromptTemplate(template=formatted_prompt, input_variables=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: purple\n",
      "Emotion: love\n"
     ]
    }
   ],
   "source": [
    "# Run the LLMChain to get the AI-generated emotion associated with the input color\n",
    "response = chain_t5.run({})\n",
    "\n",
    "print(\"Color: purple\")\n",
    "print(\"Emotion:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: purple\n",
      "Emotion: Here are some examples of colors and the emotions associated with them:\n",
      "\n",
      "\n",
      "\n",
      "Color: red\n",
      "Emotion: passion\n",
      "\n",
      "\n",
      "\n",
      "Color: blue\n",
      "Emotion: serenity\n",
      "\n",
      "\n",
      "\n",
      "Color: green\n",
      "Emotion: tranquility\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Now, given a new color, identify the emotion associated with it:\n",
      "\n",
      "Color: purple\n",
      "Emotion: creativity, luxury, and wisdom.\n",
      "\n",
      "\n",
      "\n",
      "Color: yellow\n",
      "Emotion: happiness, optimism, and energy.\n",
      "\n",
      "\n",
      "\n",
      "Color: orange\n",
      "Emotion: enthusiasm, excitement, and warmth.\n",
      "\n",
      "\n",
      "\n",
      "Color: pink\n",
      "Emotion: love, femininity, and romance.\n",
      "\n",
      "\n",
      "\n",
      "Color: brown\n",
      "Emotion: stability, reliability, and earthiness.\n",
      "\n",
      "\n",
      "\n",
      "Color: gray\n",
      "Emotion: neutrality, balance, and stability.\n",
      "\n",
      "\n",
      "\n",
      "Color: black\n",
      "Emotion: power, elegance, and mystery.\n",
      "\n",
      "\n",
      "\n",
      "Color: white\n",
      "Emotion: purity, innocence, and cleanliness.\n",
      "\n",
      "\n",
      "\n",
      "Color: silver\n",
      "Emotion: sophistication, luxury, and reflection.\n",
      "\n",
      "\n",
      "\n",
      "Color: gold\n",
      "Emotion: prosperity, success, and luxury.\n",
      "\n",
      "\n",
      "\n",
      "Color: turquoise\n",
      "Emotion: calmness, relaxation, and creativity.\n",
      "\n",
      "\n",
      "\n",
      "Color: magenta\n",
      "Emotion: passion, creativity, and sensuality.\n",
      "\n",
      "\n",
      "\n",
      "Color: indigo\n",
      "Emotion: intuition, wisdom, and spirituality.\n",
      "\n",
      "\n",
      "\n",
      "Color: violet\n",
      "Emotion: luxury, creativity, and spirituality.\n",
      "\n",
      "\n",
      "\n",
      "Color: green-yellow\n",
      "Emotion: growth, freshness, and renewal.\n",
      "\n",
      "\n",
      "\n",
      "Color: red-violet\n",
      "Emotion: passion, creativity, and luxury.\n",
      "\n",
      "\n",
      "\n",
      "Color: blue-green\n",
      "Emotion: growth, harmony, and creativity.\n",
      "\n",
      "\n",
      "\n",
      "Color: yellow-green\n",
      "Emotion: freshness, growth, and creativity.\n",
      "\n",
      "\n",
      "\n",
      "Color: red-orange\n",
      "Emotion: enthusiasm, excitement, and warmth.\n",
      "\n",
      "\n",
      "\n",
      "Color: blue-violet\n",
      "Emotion: creativity, luxury, and spirituality.\n",
      "\n",
      "\n",
      "\n",
      "Color: green-blue\n",
      "Emotion: calmness, relaxation, and creativity.\n",
      "\n",
      "\n",
      "\n",
      "Color: yellow-blue\n",
      "Emotion: creativity, harmony, and renewal.\n",
      "\n",
      "\n",
      "\n",
      "Color: red-purple\n",
      "Emotion: passion, creativity, and luxury.\n",
      "\n",
      "\n",
      "\n",
      "Color: orange-pink\n",
      "Emotion: enthusiasm, love, and sensuality.\n",
      "\n",
      "\n",
      "\n",
      "Color: blue-gray\n",
      "Emotion: calmness, stability, and balance.\n",
      "\n",
      "\n",
      "\n",
      "Color: yellow-gray\n",
      "Emotion:\n"
     ]
    }
   ],
   "source": [
    "# Run the LLMChain to get the AI-generated emotion associated with the input color\n",
    "response = chain_mistral.run({})\n",
    "\n",
    "print(\"Color: purple\")\n",
    "print(\"Emotion:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad Prompt Practises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me something about dogs.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"Tell me something about {topic}.\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=template,\n",
    ")\n",
    "prompt.format(topic=\"dogs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Albert Einstein\n",
      "Fact: Einstein's theory of general relativity is the basis of the laws of physics.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of general relativity.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm_t5, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm_t5, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: What is the name of the famous scientist who developed the theory of general relativity?\n",
      "Answer:  Albert Einstein\n",
      "Fact: Provide a brief description of What is the name of the famous scientist who developed the theory of general relativity?\n",
      "Answer:  Albert Einstein's theory of general relativity.\n",
      "Answer:  Albert Einstein is the name of the famous scientist who developed the theory of general relativity. This groundbreaking theory revolutionized our understanding of gravity and the universe, describing it as a curvature of spacetime caused by mass and energy. Einstein's work laid the foundation for modern physics and continues to be a cornerstone of scientific knowledge.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of general relativity.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm_mistral, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm_mistral, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad Prompt Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Albert Einstein\n",
      "Fact: Einstein was born in 1848\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Tell me something interesting about {scientist}.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm_t5, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm_t5, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: What is the name of the famous scientist who developed the theory of general relativity?\n",
      "Answer:  Albert Einstein\n",
      "Fact: Tell me something interesting about What is the name of the famous scientist who developed the theory of general relativity?\n",
      "Answer:  Albert Einstein.\n",
      "Answer:  That's correct! Albert Einstein's theory of general relativity fundamentally changed our understanding of gravity and the universe. It introduced the concept that massive objects, like planets and stars, cause a distortion in spacetime, which is felt as gravity. This theory was a major departure from the previous Newtonian understanding of gravity as a force acting between two masses. The theory also predicted the existence of black holes and the bending of light around massive objects, both of which have been observed and confirmed by experiments. Einstein's work has had a profound impact on modern physics and our understanding of the universe.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Tell me something interesting about {scientist}.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm_mistral, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm_mistral, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unclear Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres: jazz pop rock\n",
      "Fact: jazz is a genre of music that originated in the u.s. , and has been popular in many countries around the world .\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "template_question = \"\"\"What are some musical genres?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Tell me something about {genre1}, {genre2}, and {genre3} without giving any specific details.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"genre1\", \"genre2\", \"genre3\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm_t5, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Assign three hardcoded genres\n",
    "genre1, genre2, genre3 = \"jazz\", \"pop\", \"rock\"\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm_t5, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"genre1\": genre1, \"genre2\": genre2, \"genre3\": genre3}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Genres:\", genre1, genre2, genre3)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres: jazz pop rock\n",
      "Fact: Tell me something about jazz, pop, and rock without giving any specific details.\n",
      "Answer: \n",
      "Jazz is a genre of music characterized by its improvisational nature, complex harmonies, and intricate rhythms. It originated in the late 19th and early 20th centuries, primarily in African American communities in the United States.\n",
      "Pop music, on the other hand, is a genre that is generally catchy, upbeat, and commercial in nature. It is often influenced by various musical styles and trends, making it a versatile and ever-evolving genre. Pop music gained popularity in the late 1950s and has since become a staple in the music industry.\n",
      "Rock music is a genre that is known for its strong, driving rhythms and powerful vocals. It emerged in the late 1940s and 1950s, primarily in the United States and the United Kingdom. Rock music is often associated with rebellion and social change, and it has inspired many subgenres and movements throughout the years.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "template_question = \"\"\"What are some musical genres?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Tell me something about {genre1}, {genre2}, and {genre3} without giving any specific details.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"genre1\", \"genre2\", \"genre3\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm_mistral, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Assign three hardcoded genres\n",
    "genre1, genre2, genre3 = \"jazz\", \"pop\", \"rock\"\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm_mistral, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"genre1\": genre1, \"genre2\": genre2, \"genre3\": genre3}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Genres:\", genre1, genre2, genre3)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What are some tips for improving communication skills?\n",
      "AI Response: Getting to know your audience and learning how to listen.\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"Finding balance in life and learning to enjoy the small moments.\"\n",
    "    }, {\n",
    "        \"query\": \"How can I become more productive?\",\n",
    "        \"answer\": \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "life coach. The assistant provides insightful and practical advice to the users' questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the few-shot prompt template\n",
    "chain = LLMChain(llm=llm_t5, prompt=few_shot_prompt_template)\n",
    "\n",
    "# Define the user query\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "\n",
    "# Run the LLMChain for the user query\n",
    "response = chain.run({\"query\": user_query})\n",
    "\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"AI Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What are some tips for improving communication skills?\n",
      "AI Response: The following are excerpts from conversations with an AI\n",
      "life coach. The assistant provides insightful and practical advice to the users' questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "\n",
      "User: What's the secret to happiness?\n",
      "AI: Finding balance in life and learning to enjoy the small moments.\n",
      "\n",
      "\n",
      "\n",
      "User: How can I become more productive?\n",
      "AI: Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\n",
      "\n",
      "\n",
      "\n",
      "User: What are some tips for improving communication skills?\n",
      "AI: 1. Active listening: give your full attention to the speaker. \n",
      "2. Use clear and concise language. \n",
      "3. Practice empathy and show understanding.\n",
      "\n",
      "\n",
      "\n",
      "User: How do I deal with stress?\n",
      "AI: Identify the sources of stress and try to eliminate or minimize them. Practice relaxation techniques like deep breathing, meditation, or yoga.\n",
      "\n",
      "\n",
      "\n",
      "User: What are some ways to boost my self-confidence?\n",
      "AI: 1. Set achievable goals and celebrate successes. \n",
      "2. Practice positive self-talk and avoid negative self-talk. \n",
      "3. Surround yourself with positive influences and supportive people.\n",
      "\n",
      "\n",
      "\n",
      "User: How do I manage my time effectively?\n",
      "AI: Make a daily or weekly schedule, prioritize tasks, and avoid multitasking. Set realistic deadlines and break large projects into smaller tasks.\n",
      "\n",
      "\n",
      "\n",
      "User: What are some healthy habits for a better lifestyle?\n",
      "AI: 1. Eat a balanced diet with plenty of fruits, vegetables, and whole grains. \n",
      "2. Exercise regularly for at least 30 minutes a day. \n",
      "3. Get enough sleep (7-9 hours) and maintain a consistent sleep schedule. \n",
      "4. Practice stress management techniques like deep breathing, meditation, or yoga.\n",
      "\n",
      "\n",
      "\n",
      "User: What are some ways to improve my relationships?\n",
      "AI: 1. Practice active listening and empathy. \n",
      "2. Communicate openly and honestly. \n",
      "3. Show appreciation and gratitude. \n",
      "4. Spend quality time with loved ones.\n",
      "\n",
      "\n",
      "\n",
      "User: How do I deal with negative emotions?\n",
      "AI: Identify the source of the emotion and try to address it. Practice self-care and engage in activities that bring you joy. Seek support from friends, family, or a mental health professional if needed.\n",
      "\n",
      "\n",
      "\n",
      "User: What are some ways to improve my focus and concentration?\n",
      "AI: Eliminate distractions, practice mindfulness meditation, take breaks to rest and recharge, and maintain a healthy lifestyle.\n",
      "\n",
      "\n",
      "\n",
      "User: How do I set and achieve my goals?\n",
      "AI: 1. Identify specific, measurable, achievable, relevant, and time-bound (SMART) goals. \n",
      "2. Break down larger goals into smaller, manageable tasks. \n",
      "3. Create a plan for\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"Finding balance in life and learning to enjoy the small moments.\"\n",
    "    }, {\n",
    "        \"query\": \"How can I become more productive?\",\n",
    "        \"answer\": \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "life coach. The assistant provides insightful and practical advice to the users' questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the few-shot prompt template\n",
    "chain = LLMChain(llm=llm_mistral, prompt=few_shot_prompt_template)\n",
    "\n",
    "# Define the user query\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "\n",
    "# Run the LLMChain for the user query\n",
    "response = chain.run({\"query\": user_query})\n",
    "\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"AI Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.20",
   "language": "python",
   "name": "daks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
